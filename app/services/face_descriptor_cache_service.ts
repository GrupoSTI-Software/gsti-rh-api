import * as faceapi from 'face-api.js'
import canvas from 'canvas'
import path from 'node:path'
import https from 'node:https'
import http from 'node:http'
import fs from 'node:fs'
// import logger from '@adonisjs/core/services/logger'

const { Canvas, Image, ImageData, createCanvas } = canvas
faceapi.env.monkeyPatch({ Canvas, Image, ImageData } as any)

const MODEL_PATH = path.join(process.cwd(), 'models')

// ============ CONFIGURACI√ìN DE RENDIMIENTO ============
const CONFIG = {
  // Tama√±o m√°ximo de imagen para procesamiento (reducir = m√°s r√°pido)
  // 320 es muy r√°pido pero menos preciso, 640 es buen balance
  MAX_IMAGE_SIZE: 480,

  // Usar TinyFaceDetector si est√° disponible (5-10x m√°s r√°pido)
  // Se detecta autom√°ticamente si el modelo existe
  USE_TINY_DETECTOR: true,

  // minConfidence para SSD Mobilenet (menor = m√°s r√°pido pero puede fallar en fotos dif√≠ciles)
  SSD_MIN_CONFIDENCE: 0.5,

  // Timeout para descargas de red
  DOWNLOAD_TIMEOUT_MS: 15000,

  // Cach√© configuraci√≥n
  CACHE_MAX_SIZE: 1000,
  CACHE_TTL_MS: 60 * 60 * 1000, // 1 hora
}

/**
 * Verifica si TinyFaceDetector est√° disponible
 */
function hasTinyFaceDetector(): boolean {
  const manifestPath = path.join(MODEL_PATH, 'tiny_face_detector_model-weights_manifest.json')
  return fs.existsSync(manifestPath)
}

/**
 * Descarga imagen desde URL con timeout configurable
 */
async function downloadImageBuffer(url: string, timeoutMs: number = CONFIG.DOWNLOAD_TIMEOUT_MS): Promise<Buffer> {
  return new Promise((resolve, reject) => {
    const protocol = url.startsWith('https') ? https : http

    const request = protocol.get(url, { timeout: timeoutMs }, (res) => {
      if (res.statusCode !== 200) {
        reject(new Error(`HTTP ${res.statusCode}: Failed to download image`))
        return
      }

      const chunks: Uint8Array[] = []
      res.on('data', (chunk: Uint8Array) => chunks.push(chunk))
      res.on('end', () => resolve(Buffer.concat(chunks)))
      res.on('error', reject)
    })

    request.on('error', reject)
    request.on('timeout', () => {
      request.destroy()
      reject(new Error('Download timeout'))
    })
  })
}

/**
 * Descarga imagen con reintentos (m√°ximo 1 reintento para velocidad)
 */
async function downloadWithRetry(url: string, maxRetries: number = 1, timeoutMs: number = CONFIG.DOWNLOAD_TIMEOUT_MS): Promise<Buffer> {
  let lastError: Error | null = null

  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      return await downloadImageBuffer(url, timeoutMs)
    } catch (error) {
      lastError = error as Error
      if (attempt < maxRetries) {
        await new Promise((r) => setTimeout(r, 500)) // Espera corta
      }
    }
  }

  throw lastError || new Error('Download failed after retries')
}

/**
 * OPTIMIZACI√ìN CLAVE: Redimensiona imagen para procesamiento m√°s r√°pido
 * Una imagen de 480px es suficiente para detecci√≥n facial confiable
 */
async function resizeImageForProcessing(imageBuffer: Buffer): Promise<canvas.Image> {
  const img = await canvas.loadImage(imageBuffer)

  // Si la imagen ya es peque√±a, devolverla tal cual
  if (img.width <= CONFIG.MAX_IMAGE_SIZE && img.height <= CONFIG.MAX_IMAGE_SIZE) {
    return img
  }

  // Calcular nuevo tama√±o manteniendo aspect ratio
  const scale = CONFIG.MAX_IMAGE_SIZE / Math.max(img.width, img.height)
  const newWidth = Math.round(img.width * scale)
  const newHeight = Math.round(img.height * scale)

  // Crear canvas redimensionado
  const resizedCanvas = createCanvas(newWidth, newHeight)
  const ctx = resizedCanvas.getContext('2d')
  ctx.drawImage(img, 0, 0, newWidth, newHeight)

  // Convertir a buffer y cargar de nuevo como imagen
  const resizedBuffer = resizedCanvas.toBuffer('image/jpeg', { quality: 0.85 })
  return await canvas.loadImage(resizedBuffer)
}

/**
 * Estructura de entrada en cach√©
 */
interface CacheEntry {
  descriptor: Float32Array
  timestamp: number
  photoUrl: string
}

/**
 * Servicio de cach√© LRU para descriptores faciales
 * Optimizado para verificaci√≥n biom√©trica de alta velocidad
 */
class FaceDescriptorCacheService {
  private cache: Map<number, CacheEntry> = new Map()
  private readonly maxSize: number = CONFIG.CACHE_MAX_SIZE
  private readonly ttlMs: number = CONFIG.CACHE_TTL_MS
  private modelsLoaded: boolean = false
  private modelsLoading: Promise<void> | null = null
  private useTinyDetector: boolean = false

  /**
   * Carga los modelos de FaceAPI (singleton pattern con promise)
   * Detecta autom√°ticamente si TinyFaceDetector est√° disponible
   */
  async ensureModelsLoaded(): Promise<void> {
    if (this.modelsLoaded) return

    if (this.modelsLoading) {
      await this.modelsLoading
      return
    }

    this.modelsLoading = this.loadModelsInternal()
    await this.modelsLoading
  }

  private async loadModelsInternal(): Promise<void> {
    // const startTime = Date.now()

    // Verificar si TinyFaceDetector est√° disponible
    this.useTinyDetector = CONFIG.USE_TINY_DETECTOR && hasTinyFaceDetector()

    const modelsToLoad: Promise<void>[] = [
      faceapi.nets.faceLandmark68TinyNet.loadFromDisk(MODEL_PATH),
      faceapi.nets.faceRecognitionNet.loadFromDisk(MODEL_PATH),
    ]

    if (this.useTinyDetector) {
      // logger.info('üöÄ Usando TinyFaceDetector (modo r√°pido)')
      modelsToLoad.push(faceapi.nets.tinyFaceDetector.loadFromDisk(MODEL_PATH))
    } else {
      // logger.info('üì¶ Usando SSD Mobilenet (modo est√°ndar)')
      modelsToLoad.push(faceapi.nets.ssdMobilenetv1.loadFromDisk(MODEL_PATH))
    }

    await Promise.all(modelsToLoad)
    this.modelsLoaded = true

    // logger.info(`‚úÖ Modelos cargados en ${Date.now() - startTime}ms`)
  }

  /**
   * Obtiene descriptor del cach√© si existe y es v√°lido
   */
  get(employeeId: number, photoUrl: string): Float32Array | null {
    const entry = this.cache.get(employeeId)
    if (!entry) return null

    const isExpired = Date.now() - entry.timestamp > this.ttlMs
    const urlChanged = entry.photoUrl !== photoUrl

    if (isExpired || urlChanged) {
      this.cache.delete(employeeId)
      return null
    }

    // Mover al final (LRU - m√°s reciente)
    this.cache.delete(employeeId)
    this.cache.set(employeeId, entry)

    return entry.descriptor
  }

  /**
   * Almacena descriptor en cach√©
   */
  set(employeeId: number, descriptor: Float32Array, photoUrl: string): void {
    if (this.cache.size >= this.maxSize) {
      const oldestKey = this.cache.keys().next().value
      if (oldestKey !== undefined) {
        this.cache.delete(oldestKey)
      }
    }

    this.cache.set(employeeId, {
      descriptor,
      timestamp: Date.now(),
      photoUrl,
    })
  }

  /**
   * Invalida entrada de cach√© para un empleado
   */
  invalidate(employeeId: number): void {
    this.cache.delete(employeeId)
  }

  /**
   * Limpia todo el cach√©
   */
  clear(): void {
    this.cache.clear()
  }

  /**
   * OPTIMIZADO: Detecta rostro usando el mejor detector disponible
   * TinyFaceDetector: ~50-100ms | SSD Mobilenet: ~300-800ms
   */
  private async detectFace(img: canvas.Image): Promise<faceapi.WithFaceDescriptor<faceapi.WithFaceLandmarks<{ detection: faceapi.FaceDetection }, faceapi.FaceLandmarks68>> | undefined> {
    if (this.useTinyDetector) {
      // TinyFaceDetector es 5-10x m√°s r√°pido
      const options = new faceapi.TinyFaceDetectorOptions({
        inputSize: 320, // 320 es m√°s r√°pido, 416/512 m√°s preciso
        scoreThreshold: 0.5,
      })
      return await faceapi
        .detectSingleFace(img, options)
        .withFaceLandmarks(true)
        .withFaceDescriptor()
    } else {
      // SSD Mobilenet - m√°s lento pero disponible
      const options = new faceapi.SsdMobilenetv1Options({
        minConfidence: CONFIG.SSD_MIN_CONFIDENCE,
      })
      return await faceapi
        .detectSingleFace(img, options)
        .withFaceLandmarks(true)
        .withFaceDescriptor()
    }
  }

  /**
   * Calcula descriptor facial de una imagen (URL o buffer)
   * OPTIMIZADO: Redimensiona imagen para procesamiento m√°s r√°pido
   */
  async computeDescriptor(imageSource: string | Buffer): Promise<Float32Array | null> {
    await this.ensureModelsLoaded()

    try {
      let img: canvas.Image

      if (typeof imageSource === 'string' && imageSource.startsWith('http')) {
        const imageBuffer = await downloadWithRetry(imageSource, 1, CONFIG.DOWNLOAD_TIMEOUT_MS)
        img = await resizeImageForProcessing(imageBuffer)
      } else if (typeof imageSource === 'string') {
        // Ruta local
        const localBuffer = fs.readFileSync(imageSource)
        img = await resizeImageForProcessing(localBuffer)
      } else {
        img = await resizeImageForProcessing(imageSource)
      }

      const detection = await this.detectFace(img)
      return detection?.descriptor || null
    } catch (error) {
      // logger.error({ error }, 'Error computing face descriptor')
      return null
    }
  }

  /**
   * Obtiene descriptor de empleado (desde cach√© o lo calcula)
   */
  async getEmployeeDescriptor(
    employeeId: number,
    photoUrl: string,
    getImageSource: () => Promise<string | Buffer | null>
  ): Promise<Float32Array | null> {
    // 1. Intentar obtener del cach√©
    const cached = this.get(employeeId, photoUrl)
    if (cached) {
      return cached
    }

    // 2. Obtener imagen y calcular descriptor
    const imageSource = await getImageSource()
    if (!imageSource) return null

    const descriptor = await this.computeDescriptor(imageSource)
    if (!descriptor) return null

    // 3. Guardar en cach√©
    this.set(employeeId, descriptor, photoUrl)

    return descriptor
  }

  /**
   * Verifica dos descriptores faciales
   */
  compareDescriptors(
    descriptor1: Float32Array,
    descriptor2: Float32Array,
    threshold: number = 0.6
  ): { match: boolean; distance: number; threshold: number } {
    const distance = faceapi.euclideanDistance(descriptor1, descriptor2)
    return {
      match: distance < threshold,
      distance,
      threshold,
    }
  }

  /**
   * Estad√≠sticas del cach√©
   */
  getStats(): { size: number; maxSize: number; useTinyDetector: boolean } {
    return {
      size: this.cache.size,
      maxSize: this.maxSize,
      useTinyDetector: this.useTinyDetector,
    }
  }

  /**
   * Pre-warmup: Cargar modelos anticipadamente
   * Llamar esto al iniciar la aplicaci√≥n para eliminar cold start
   */
  async warmup(): Promise<void> {
    // logger.info('üî• Iniciando warmup de modelos de reconocimiento facial...')
    // const start = Date.now()
    await this.ensureModelsLoaded()
    // logger.info(`üî• Warmup completado en ${Date.now() - start}ms`)
  }
}

// Singleton instance
export const faceDescriptorCache = new FaceDescriptorCacheService()
export default FaceDescriptorCacheService
